import streamlit as st
import requests
import pandas as pd
import time
import urllib3
from datetime import datetime
import io
import re
import logging

# --- 0. ç¯å¢ƒè®¾ç½® ---
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

st.set_page_config(
    page_title="åŸºé‡‘ç›‘æ§ Pro (è‡ªåŠ¨è¯†åˆ«ç‰ˆ)",
    layout="wide",
    page_icon="ğŸš€"
)

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Referer": "http://fundf10.eastmoney.com/"
}

# æŒ‡æ•°åç§°åˆ°ä»£ç çš„æ˜ å°„
INDEX_NAME_TO_CODE = {
    # ä¸»è¦å®½åŸºæŒ‡æ•°
    "æ²ªæ·±300": "sh000300",
    "ä¸­è¯500": "sh000905",
    "ä¸Šè¯50": "sh000016",
    "åˆ›ä¸šæ¿æŒ‡": "sz399006",
    "æ·±è¯æˆæŒ‡": "sz399001",
    "ä¸­è¯1000": "sh000852",
    "ç§‘åˆ›50": "sh000688",
    "ä¸Šè¯æŒ‡æ•°": "sh000001",
    "æ·±è¯100": "sz399330",
    "ä¸­è¯800": "sh000906",
    "ä¸­è¯200": "sh000904",
    "ä¸­è¯100": "sh000903",
    "ä¸­è¯å…¨æŒ‡": "sh000985",
    "ä¸­è¯Aè‚¡": "sh000985",
    "ä¸­è¯æµé€š": "sh000902",

    # è¡Œä¸šæŒ‡æ•°
    "ä¸­è¯ç™½é…’": "sz399997",
    "ä¸­è¯åŒ»ç–—": "sz399989",
    "ä¸­è¯åŒ»è¯": "sh000933",
    "ä¸­è¯æ–°èƒ½": "sh399808",
    "ä¸­è¯å†›å·¥": "sh399967",
    "ä¸­è¯ä¼ åª’": "sh399971",
    "ä¸­è¯è®¡ç®—æœº": "sh399935",
    "ä¸­è¯ç”µå­": "sh399811",
    "ä¸­è¯åŠå¯¼ä½“": "sh399673",
    "ä¸­è¯èŠ¯ç‰‡": "sh399673",
    "ä¸­è¯5Gé€šä¿¡": "sh399994",
    "ä¸­è¯äººå·¥æ™ºèƒ½": "sh399971",
    "ä¸­è¯å¤§æ•°æ®": "sh399415",
    "ä¸­è¯äº‘è®¡ç®—": "sh399413",
    "ä¸­è¯åŒºå—é“¾": "sh399254",
    "ä¸­è¯é‡‘èç§‘æŠ€": "sh399699",
    "ä¸­è¯é“¶è¡Œ": "sh399986",
    "ä¸­è¯è¯åˆ¸": "sh399975",
    "åˆ¸å•†": "sh399975",
    "è¯åˆ¸": "sh399975",
    "ä¸­è¯ä¿é™©": "sh399809",
    "ä¸­è¯åœ°äº§": "sh399983",
    "ä¸­è¯æœ‰è‰²": "sh399805",
    "ä¸­è¯ç…¤ç‚­": "sh399998",
    "ä¸­è¯é’¢é“": "sh399969",
    "ä¸­è¯åŸºå»º": "sh399995",
    "ä¸­è¯å†œä¸š": "sh399986",
    "ä¸­è¯æ¶ˆè´¹": "sh399977",
    "ä¸­è¯çº¢åˆ©": "sh000922",
    "ä¸­è¯ç¯ä¿": "sh399806",
    "ä¸­è¯TMT": "sh399998",
    "ä¸­è¯äº’è”ç½‘": "sh399677",
    "ä¸­è¯æ¸¸æˆ": "sh399418",
    "ä¸­è¯åŠ¨æ¼«æ¸¸æˆ": "sh930901",
    "ä¸­è¯å½±è§†": "sh399418",
    "ä¸­è¯ç§‘æŠ€50ç­–ç•¥": "sh000931",
    "ä¸­è¯ç§‘æŠ€": "sh000931",
    "ä¸­è¯ç§‘æŠ€50": "sh000931",

    # ä¸»é¢˜æŒ‡æ•°
    "ä¸­è¯æ–°èƒ½æºè½¦": "sh399976",
    "ä¸­è¯æ–°èƒ½æº": "sh399808",
    "ä¸­è¯å…‰ä¼": "sh399618",
    "ä¸­è¯ç¨€åœŸ": "sh399715",
    "ä¸­è¯åˆ›æ–°è¯": "sh931152",
    "ä¸­è¯åŒ»ç–—å™¨æ¢°": "sh931152",
    "ä¸­è¯ç”Ÿç‰©ç§‘æŠ€": "sh399993",
    "ä¸­è¯å…»è€": "sh399993",
    "ä¸­è¯é£Ÿå“é¥®æ–™": "sh399996",
    "ä¸­è¯å®¶ç”¨ç”µå™¨": "sh399996",

    # æ¸¯è‚¡æŒ‡æ•°
    "æ’ç”ŸæŒ‡æ•°": "r_hkHSI",
    "æ’ç”Ÿç§‘æŠ€": "r_hkHSTECH",
    "æ’ç”Ÿå›½ä¼": "r_hkHSCEI",
    "æ’ç”ŸåŒ»ç–—": "r_hkHSHKI",
    "æ’ç”Ÿæ¶ˆè´¹": "r_hkHSCSI",
    "æ’ç”Ÿäº’è”ç½‘": "r_hkHSIII",
    "æ¸¯è‚¡é€šæ–°ç»æµ": "r_hkHSNEI",

    # ç¾è‚¡æŒ‡æ•° - ä½¿ç”¨ETFä½œä¸ºæ›¿ä»£
    "çº³æ–¯è¾¾å…‹100": "s_usQQQ",
    "çº³æ–¯è¾¾å…‹": "s_usQQQ",
    "çº³æ–¯è¾¾å…‹ç»¼åˆ": "s_usQQQ",
    "æ ‡æ™®500": "s_usSPY",
    "æ ‡æ™®500æŒ‡æ•°": "s_usSPY",
    "é“ç¼æ–¯": "s_usDIA",
    "é“ç¼æ–¯å·¥ä¸š": "s_usDIA",
    "é“ç¼æ–¯æŒ‡æ•°": "s_usDIA",
    "ç½—ç´ 2000": "s_usIWM",

    # ä¸­æ¦‚è‚¡æŒ‡æ•° - ä½¿ç”¨ETFä½œä¸ºæ›¿ä»£
    "ä¸­æ¦‚äº’è”ç½‘": "s_usKWEB",
    "ä¸­å›½äº’è”ç½‘": "s_usKWEB",
    "ä¸­è¯æµ·å¤–ä¸­å›½äº’è”ç½‘": "s_usKWEB",
    "ä¸­å›½äº’è”": "s_usKWEB",
    "ä¸­æ¦‚è‚¡": "s_usKWEB",
}


# --- 1. å·¥å…·å‡½æ•° ---

def get_tencent_code(stock_code, fund_name):
    """è½¬æ¢è‚¡ç¥¨ä»£ç ä¸ºè…¾è®¯æ ¼å¼"""
    code = str(stock_code).strip()
    if '.' in code:
        code = code.split('.')[0]

    f_name = str(fund_name)
    is_overseas_fund = any(
        x in f_name for x in
        ["æ¸¯", "æ’ç”Ÿ", "QDII", "æµ·å¤–", "äº’è”ç½‘", "ç§‘æŠ€", "Nasdaq", "æ ‡æ™®", "ç¾è‚¡", "å…¨çƒ"])

    if code.isdigit():
        if is_overseas_fund and len(code) <= 5:
            return f"r_hk{code.zfill(5)}"
        else:
            full_code = code.zfill(6)
            if full_code.startswith(('6', '9')):
                return f"sh{full_code}"
            elif full_code.startswith(('0', '3')):
                return f"sz{full_code}"
            elif full_code.startswith(('4', '8')):
                return f"bj{full_code}"
            else:
                return f"sz{full_code}"

    if code.isalpha():
        return f"s_us{code.upper()}"

    return code


def extract_index_from_fund_name(fund_name):
    """ä»åŸºé‡‘åç§°ä¸­æå–æŒ‡æ•°åç§°"""
    if not fund_name:
        return None

    # æŒ‰é•¿åº¦é™åºæ’åˆ—ï¼Œä¼˜å…ˆåŒ¹é…æ›´é•¿çš„åç§°
    for index_name in sorted(INDEX_NAME_TO_CODE.keys(), key=len, reverse=True):
        if index_name in fund_name:
            return index_name
    return None


def is_garbage(text):
    """è¿‡æ»¤æ‚è´¨"""
    if not text or len(text) < 2:
        return True
    if re.match(r'^[0-9,.\-%]+$', text):
        return True
    garbage = ["è¯¦æƒ…", "è¡Œæƒ…", "è‚¡å§", "ä»£ç ", "åç§°", "èµ„è®¯", "æ¯”ä¾‹", "åºå·", "å å‡€å€¼"]
    if any(x in text for x in garbage):
        return True
    return False


def safe_request(url, headers=None, max_retries=3, sleep_time=0.5):
    """é€šç”¨é‡è¯•è¯·æ±‚å‡½æ•°"""
    for i in range(max_retries):
        try:
            r = requests.get(url, headers=headers, timeout=10, verify=False)
            if r.status_code == 200 and len(r.content) > 0:
                return r
        except requests.exceptions.RequestException as e:
            logger.warning(f"è¯·æ±‚å¤±è´¥ (å°è¯• {i + 1}/{max_retries}): {url[:50]}... é”™è¯¯: {e}")
            if i == max_retries - 1:
                break
            time.sleep(sleep_time * (i + 1))
    return None


def get_tencent_quotes(tencent_codes):
    """è·å–è…¾è®¯è¡Œæƒ…ï¼ˆæ”¯æŒAè‚¡ã€æ¸¯è‚¡ã€ç¾è‚¡ï¼‰"""
    if not tencent_codes:
        return {}

    def safe_float(v):
        try:
            if not v or v == '':
                return 0.0
            return float(v)
        except (ValueError, TypeError):
            return 0.0

    res = {}
    code_list = list(tencent_codes)
    BATCH_SIZE = 60

    for i in range(0, len(code_list), BATCH_SIZE):
        batch_codes = code_list[i:i + BATCH_SIZE]
        url = f"http://qt.gtimg.cn/q={','.join(batch_codes)}"

        r = safe_request(url, headers={"Referer": "http://finance.qq.com/"}, max_retries=3)

        if r is None:
            continue

        try:
            content = r.content.decode('gbk', errors='ignore')
            lines = content.split(';')

            for line in lines:
                line = line.strip()
                if not line or '="' not in line:
                    continue

                try:
                    parts = line.split('="')
                    if len(parts) < 2:
                        continue

                    var_name = parts[0]
                    data_str = parts[1].rstrip('"')

                    # æå–ä»£ç 
                    if '_sh' in var_name:
                        code = 'sh' + var_name.split('_sh')[1]
                    elif '_sz' in var_name:
                        code = 'sz' + var_name.split('_sz')[1]
                    elif '_hk' in var_name:
                        code = 'r_hk' + var_name.split('_hk')[1]
                    elif '_us' in var_name:
                        code = 's_us' + var_name.split('_us')[1]
                    else:
                        continue

                    # è§£ææ•°æ®å­—æ®µ
                    fields = data_str.split('~')
                    if len(fields) < 6:
                        continue

                    # ç¾è‚¡ETF: å­—æ®µ5æ˜¯æ¶¨è·Œå¹…%
                    if code.startswith('s_us'):
                        change_pct = safe_float(fields[5])
                        res[code] = change_pct
                    else:
                        # Aè‚¡/æ¸¯è‚¡: å­—æ®µ32æ˜¯æ¶¨è·Œå¹…%
                        change_pct = safe_float(fields[32]) if len(fields) > 32 else 0.0
                        res[code] = change_pct

                except Exception as e:
                    continue

        except Exception as e:
            continue

    return res


# --- 2. æ ¸å¿ƒæŠ“å–å‡½æ•° ---

@st.cache_data(ttl=3600)
def fetch_fund_data(fund_code):
    """è·å–åŸºé‡‘æŒä»“æ•°æ®"""
    url = f"http://fundf10.eastmoney.com/FundArchivesDatas.aspx?type=jjcc&code={fund_code}&topline=200"

    r = safe_request(url, headers=HEADERS)

    if r is None:
        return None, "ç½‘ç»œè¶…æ—¶", "", False, None

    try:
        if 'content:"' not in r.text:
            return None, "æ¥å£æ‹¦æˆª", "", False, None

        raw_html = r.text.split('content:"')[1].split('",')[0]
        raw_html = raw_html.replace(r'\"', '"').replace(r'\/', '/')

        # 1. æå–åŸºé‡‘åç§°
        name_match = re.search(r"title='(.*?)'", raw_html)
        fund_name = name_match.group(1) if name_match else f"åŸºé‡‘{fund_code}"

        # 2. æ£€æŸ¥æ˜¯å¦æ˜¯ETFè”æ¥åŸºé‡‘
        is_etf_link = "ETFè”æ¥" in fund_name

        # 3. å¦‚æœæ˜¯ETFè”æ¥åŸºé‡‘ï¼Œä»åŸºé‡‘åç§°ä¸­æå–è·Ÿè¸ªçš„æŒ‡æ•°
        tracked_index = None
        if is_etf_link:
            tracked_index = extract_index_from_fund_name(fund_name)

        # 4. ç‰©ç†æˆªæ–­ï¼šåªä¿ç•™ç¬¬ä¸€ä¸ªå­£åº¦
        quarters = list(re.finditer(r'\d{4}å¹´\då­£åº¦è‚¡ç¥¨æŠ•èµ„æ˜ç»†', raw_html))
        if len(quarters) > 1:
            raw_html = raw_html[:quarters[1].start()]

        date_match = re.search(r'æˆªæ­¢è‡³ï¼š(\d{4}-\d{2}-\d{2})', raw_html)
        report_date = date_match.group(1) if date_match else "æœ€æ–°"

        # 5. è§£æè¡¨æ ¼
        dfs = pd.read_html(io.StringIO(raw_html))
        holdings = []

        for df in dfs:
            df = df.astype(str)
            for _, row in df.iterrows():
                vals = [str(v).strip() for v in row.values]
                if len(vals) < 5:
                    continue

                s_code, s_name, pct = None, None, 0.0
                c_idx = -1

                # å¯»æ‰¾ä»£ç é”šç‚¹
                for i, v in enumerate(vals):
                    if v.isdigit() and 1 <= len(v) <= 6:
                        if i > 0 or len(v) >= 4:
                            s_code = v
                            c_idx = i
                            break
                    elif v.isalpha() and 1 < len(v) <= 5 and v.isupper():
                        s_code, c_idx = v, i
                        break

                if s_code and c_idx != -1:
                    if c_idx + 1 < len(vals) and not is_garbage(vals[c_idx + 1]):
                        s_name = vals[c_idx + 1]
                    elif c_idx - 1 >= 0 and not is_garbage(vals[c_idx - 1]):
                        s_name = vals[c_idx - 1]

                # æŸ¥æ‰¾æŒä»“å æ¯”
                for v in vals:
                    if '%' in v:
                        try:
                            pct = float(v.replace('%', '').replace(',', ''))
                            break
                        except:
                            pass

                if s_code and s_name and pct > 0:
                    tencent_code = get_tencent_code(s_code, fund_name)
                    holdings.append({
                        "åç§°": s_name,
                        "ä»£ç ": s_code,
                        "æŒä»“å æ¯”": pct,
                        "tencent_code": tencent_code
                    })

        if holdings:
            res_df = pd.DataFrame(holdings).drop_duplicates(subset=['ä»£ç '])
            res_df = res_df.sort_values(by='æŒä»“å æ¯”', ascending=False).head(15)
            return res_df, fund_name, report_date, is_etf_link, tracked_index

    except Exception as e:
        logger.error(f"è§£æåŸºé‡‘æ•°æ®å¼‚å¸¸: {e}")
        return None, f"å¼‚å¸¸: {e}", "", False, None

    return None, "æ— æ•°æ®", "", False, None


# --- 3. ç•Œé¢é€»è¾‘ ---

with st.sidebar:
    st.header("âš™ï¸ ç›‘æ§åˆ—è¡¨ç®¡ç†")

    if 'fund_list' not in st.session_state:
        st.session_state.fund_list = ['011102', '010434', '161725', '020989']

    # æ·»åŠ 
    new_code = st.text_input("â• æ·»åŠ åŸºé‡‘ä»£ç  (å›è½¦)")
    if new_code:
        c = new_code.strip()
        if c and c not in st.session_state.fund_list:
            st.session_state.fund_list.append(c)
            st.rerun()

    st.markdown("---")
    # å¿«é€Ÿç§»é™¤
    st.subheader("ğŸ—‘ï¸ å¿«é€Ÿç§»é™¤")
    updated_list = st.multiselect(
        "ç‚¹å‡»ä»£ç æ—çš„ x ç§»é™¤åŸºé‡‘:",
        options=st.session_state.fund_list,
        default=st.session_state.fund_list
    )
    if updated_list != st.session_state.fund_list:
        st.session_state.fund_list = updated_list
        st.rerun()

    freq = st.slider("åˆ·æ–°é¢‘ç‡ (ç§’)", 5, 60, 15)

    # è°ƒè¯•ä¿¡æ¯
    st.markdown("---")
    st.subheader("ğŸ” è°ƒè¯•ä¿¡æ¯")
    show_debug = st.checkbox("æ˜¾ç¤ºè°ƒè¯•æ—¥å¿—")

st.title("ğŸš€ åŸºé‡‘æŒä»“å®æ—¶ç©¿é€ç›‘æ§ (è‡ªåŠ¨è¯†åˆ«ç‰ˆ)")
st.markdown(f"æœ€åæ›´æ–°: `{datetime.now().strftime('%H:%M:%S')}`")

# è·å–æ•°æ®
fund_results = {}
all_tencent_codes = set()
all_index_codes = set()

# è¿›åº¦æ¡
progress_bar = st.progress(0)
for idx, code in enumerate(st.session_state.fund_list):
    df, name, date, is_etf_link, tracked_index = fetch_fund_data(code)
    time.sleep(0.3)

    fund_results[code] = {
        "df": df,
        "name": name,
        "date": date,
        "is_etf_link": is_etf_link,
        "tracked_index": tracked_index
    }

    if df is not None and not is_etf_link:
        all_tencent_codes.update(df['tencent_code'].tolist())

    if is_etf_link and tracked_index:
        index_code = INDEX_NAME_TO_CODE.get(tracked_index)
        if index_code:
            all_index_codes.add(index_code)

    progress_bar.progress((idx + 1) / len(st.session_state.fund_list))

progress_bar.empty()

# è·å–è¡Œæƒ…
all_codes = list(all_tencent_codes) + list(all_index_codes)
quotes = get_tencent_quotes(all_codes)

# è°ƒè¯•ä¿¡æ¯
if show_debug:
    st.subheader("è°ƒè¯•æ—¥å¿—")
    st.write(f"æ€»è‚¡ç¥¨/æŒ‡æ•°ä»£ç æ•°: {len(all_codes)}")
    st.write(f"æˆåŠŸè·å–è¡Œæƒ…: {len(quotes)}")

    missing = set(all_codes) - set(quotes.keys())
    if missing:
        st.warning(f"æœªè·å–åˆ°è¡Œæƒ… ({len(missing)}ä¸ª): {list(missing)[:10]}")

# æ¸²æŸ“
if not st.session_state.fund_list:
    st.info("åˆ—è¡¨ä¸ºç©ºï¼Œè¯·åœ¨ä¾§è¾¹æ æ·»åŠ ã€‚")
else:
    cols = st.columns(3)
    for i, code in enumerate(st.session_state.fund_list):
        with cols[i % 3]:
            data = fund_results.get(code)

            if not data or data['df'] is None:
                with st.container(border=True):
                    st.error(f"åŸºé‡‘ {code} åŠ è½½å¤±è´¥")
                    st.caption(f"åŸå› : {data['name'] if data else 'æœªçŸ¥'}")
                continue

            df = data['df'].copy()
            is_etf_link = data.get('is_etf_link', False)
            tracked_index = data.get('tracked_index', '')

            # åˆ¤æ–­æ˜¯å¦æ˜¯ETFè”æ¥åŸºé‡‘
            if is_etf_link:
                # ETFè”æ¥åŸºé‡‘ï¼šä½¿ç”¨æŒ‡æ•°æ¶¨è·Œå¹…
                if tracked_index:
                    index_code = INDEX_NAME_TO_CODE.get(tracked_index)
                    if index_code:
                        est = quotes.get(index_code, 0.0)
                        etf_note = f"ğŸ“Š ETFè”æ¥åŸºé‡‘ (è·Ÿè¸ª{tracked_index})"
                    else:
                        est = 0.0
                        etf_note = f"âš ï¸ æŒ‡æ•°'{tracked_index}'æœªæ‰¾åˆ°å¯¹åº”ä»£ç "
                else:
                    est = 0.0
                    etf_note = "âš ï¸ æœªèƒ½è¯†åˆ«è·Ÿè¸ªæŒ‡æ•°"
            else:
                # æ™®é€šåŸºé‡‘ï¼šä½¿ç”¨æŒä»“åŠ æƒè®¡ç®—
                df['æ¶¨è·Œ'] = df['tencent_code'].map(lambda x: quotes.get(x, 0.0))
                total_w = df['æŒä»“å æ¯”'].sum()
                est = (df['æ¶¨è·Œ'] * df['æŒä»“å æ¯”']).sum() / total_w if total_w > 0 else 0
                etf_note = None

            with st.container(border=True):
                color = "#ff4b4b" if est >= 0 else "#09ab3b"
                st.subheader(data['name'])
                st.caption(f"ä»£ç : {code} | æˆªæ­¢æ—¥æœŸ: {data['date']}")

                if etf_note:
                    st.caption(etf_note)

                st.markdown(f"<h1 style='color:{color};text-align:center;'>{est:+.2f}%</h1>",
                            unsafe_allow_html=True)

                # æ˜¾ç¤ºæŒä»“è¡¨æ ¼
                if is_etf_link:
                    # ETFè”æ¥åŸºé‡‘æ˜¾ç¤ºæç¤ºä¿¡æ¯
                    st.info(
                        "ETFè”æ¥åŸºé‡‘ä¸»è¦æŠ•èµ„äºç›®æ ‡ETFï¼Œä¸ç›´æ¥æŒæœ‰è‚¡ç¥¨ã€‚å·²æ ¹æ®è·Ÿè¸ªæŒ‡æ•°è®¡ç®—ä¼°ç®—æ¶¨è·Œå¹…ã€‚")
                else:
                    # æ™®é€šåŸºé‡‘æ˜¾ç¤ºæŒä»“
                    valid_quotes = df[df['æ¶¨è·Œ'] != 0].shape[0]
                    total_stocks = df.shape[0]

                    if valid_quotes < total_stocks:
                        st.caption(f"âš ï¸ è¡Œæƒ…è·å–: {valid_quotes}/{total_stocks}")

                    st.dataframe(
                        df[['åç§°', 'ä»£ç ', 'æŒä»“å æ¯”', 'æ¶¨è·Œ']],
                        column_config={
                            "æŒä»“å æ¯”": st.column_config.NumberColumn(format="%.2f%%"),
                            "æ¶¨è·Œ": st.column_config.NumberColumn(format="%.2f%%")
                        },
                        hide_index=True,
                        width='stretch',
                        height=400
                    )

time.sleep(freq)
st.rerun()
